title = "Configuration to finetune SAM2 on all datasets with the original loss"

[training]
points = true
box = true
negative_points = true
mask_prompt = true
n_points = 5
n_neg_points = 5
negative_points_inside_box = true
points_near_center = 4
random_box_shift = 20
mask_prompt_type = 'loose_dilation' # 'truth', 'morphology', 'scribble', 'loose_dilation'
box_around_prompt_mask = false
use_img_embeddings = false

batch_size = 16
lr = 1e-5
weight_decay = 1e-4
epochs = 30
train_from_last_checkpoint = true
last_checkpoint_path = '/content/drive/MyDrive/TFE/results/finetuning/sam2/all_original_loss/finetuning_all_original_loss_last_checkpoint.pt'
last_model_path = '/content/drive/MyDrive/TFE/results/finetuning/sam2/all_original_loss/finetuning_all_original_loss_last_model.pt'
model_save_dir = '/content/drive/MyDrive/TFE/results/finetuning/sam2/all_original_loss/'

[validation]
frequency = 1

[sam2]
model_name = 'finetuning_all_original_loss'
model_type = 'sam2.1_hiera_b+.yaml'
train_prompt_encoder = true
train_mask_decoder = true
input_size = 1024
weight_path = ''

[misc]
device = 'cuda'
wandb = true
project_name = 'Finetuning_SAM2_ALL_ORIGINAL_LOSS'